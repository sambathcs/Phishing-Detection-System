import streamlit as st
import pandas as pd
import joblib
import requests
import time
import matplotlib.pyplot as plt
import numpy as np
from bs4 import BeautifulSoup  # Extracts website content

# âœ… Move this line to the first Streamlit command
st.set_page_config(page_title="Phishing Detection System", page_icon="ğŸ”", layout="wide")

# âœ… Load the phishing detection model with caching
@st.cache_resource
def load_model():
    return joblib.load("phishing_model.pkl")

model = load_model()

# âœ… Get the number of features expected by the model
num_features = model.n_features_in_

# ğŸ¯ Sidebar - User Input Features
st.sidebar.title("ğŸ”¹ Enter Website Features")
feature_inputs = [st.sidebar.selectbox(f"Feature {i+1}", [0, 1]) for i in range(num_features)]
user_input = np.array([feature_inputs]).reshape(1, -1)

# ğŸ¯ Main Page - Title
st.markdown("<h1 style='text-align: center;'>ğŸ” Phishing Detection System</h1>", unsafe_allow_html=True)

# âœ… Machine Learning Model Prediction
try:
    prediction = model.predict(user_input)
    probability = model.predict_proba(user_input)[0]

    st.subheader("ğŸ” Prediction Result")
    if prediction[0] == 1:
        st.error("ğŸš¨ The website is **Phishing**!")
    else:
        st.success("âœ… The website is **Safe**!")

    # ğŸ¯ Confidence Score (Probability)
    st.subheader("ğŸ“Š Confidence Score")
    fig, ax = plt.subplots()
    ax.bar(["Safe", "Phishing"], [probability[0], probability[1]], color=["green", "red"])
    st.pyplot(fig)

except ValueError as e:
    st.error(f"âš ï¸ Model Error: {str(e)}")
    st.stop()

# ğŸš€ VirusTotal API Key (Use Environment Variable)
VT_API_KEY = st.secrets["VIRUSTOTAL_API_KEY"]  # Store API key securely

# âœ… Function to check URL using VirusTotal API
def check_url_virustotal(url):
    vt_url = "https://www.virustotal.com/api/v3/urls"
    headers = {"x-apikey": VT_API_KEY}
    data = {"url": url}

    # ğŸ•µï¸â€â™‚ï¸ Submit URL for scanning
    response = requests.post(vt_url, headers=headers, data=data)

    if response.status_code == 200:
        analysis_id = response.json()["data"]["id"]
        report_url = f"https://www.virustotal.com/api/v3/analyses/{analysis_id}"

        # â³ Wait for analysis (VirusTotal takes time)
        time.sleep(10)  # Allow time for scanning
        report_response = requests.get(report_url, headers=headers)

        if report_response.status_code == 200:
            results = report_response.json()
            malicious_count = results["data"]["attributes"]["stats"]["malicious"]

            if malicious_count > 0:
                return f"ğŸš¨ **This URL is flagged as malicious by {malicious_count} security vendors!**"
            else:
                return "âœ… **This URL is safe according to VirusTotal!**"
    
    return "âš ï¸ Unable to check URL at the moment."

# âœ… Function to analyze website content for phishing keywords
def analyze_website_content(url):
    try:
        response = requests.get(url, timeout=5)
        soup = BeautifulSoup(response.text, "html.parser")
        text = soup.get_text().lower()

        # ğŸ•µï¸â€â™‚ï¸ Phishing-related keywords
        phishing_keywords = ["verify", "login", "bank", "account", "password", "security", "update", "urgent", "restricted"]
        
        matches = [word for word in phishing_keywords if word in text]
        
        return matches
    except:
        return None

# ğŸŒ **Website URL Analysis Section**
st.subheader("ğŸŒ Check Website URL")
url = st.text_input("Enter a website URL to analyze:")

if st.button("ğŸ” Analyze Website"):
    if url:
        try:
            # âœ… Step 1: Check if website is accessible
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                st.success("âœ… Website is accessible!")
            else:
                st.warning(f"âš ï¸ Website might be down! Status Code: {response.status_code}")

            # âœ… Step 2: Check website using VirusTotal API
            vt_result = check_url_virustotal(url)
            st.write(vt_result)

            # âœ… Step 3: Analyze website content for phishing indicators
            phishing_matches = analyze_website_content(url)
            if phishing_matches is None:
                st.warning("âš ï¸ Unable to extract website content.")
            elif len(phishing_matches) > 0:
                st.error(f"ğŸš¨ Warning! Phishing-related words found: {', '.join(phishing_matches)}")
            else:
                st.success("âœ… No obvious phishing keywords detected on this website.")
        
        except:
            st.error("ğŸš¨ Unable to reach the website!")

# âœ… **Success Message**
st.markdown("<div style='text-align: center; color: green; font-weight: bold;'>âœ… App is running successfully!</div>", unsafe_allow_html=True)
